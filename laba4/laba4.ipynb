{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu116 True\n"
     ]
    }
   ],
   "source": [
    "import torchdata\n",
    "import torch\n",
    "from gensim.models import FastText\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IGNORE_SAVED_FILES = True\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "vectorizer = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../Data/anek_utf8/anek_utf8.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r =  data.replace('<|startoftext|>', '').split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_simple_data_pipe(date_pipe: torchdata.datapipes.iter.IterDataPipe, f=lambda a: a, n=10) -> None:\n",
    "  print(type(date_pipe))\n",
    "  x = 0\n",
    "  for sample in date_pipe:\n",
    "    print(f(sample))\n",
    "    if x == n:\n",
    "      break\n",
    "    x +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_patterns_to_tags_replaser2(text: str):\n",
    "    text = re.sub(r'\\d+\\:\\d+\\:\\d+', ' <TIME> ', text)\n",
    "    text = re.sub(r'\\d+\\:\\d+', ' <TIME> ', text)\n",
    "    text = re.sub(r'\\+{,1}\\d{1,3}\\({,1}[\\-\\s]{,1}\\d{3}\\){,1}[\\-\\s]{,1}\\d{3}[\\-\\s]{,1}\\d{2}[\\-\\s]{,1}\\d{2}', ' <PHONE> ', text)\n",
    "    text = re.sub('\\d+/\\d+/\\d+', ' <DATE> ', text)\n",
    "    text = re.sub('\\d+-\\d+-\\d+', ' <DATE> ', text)\n",
    "    text = re.sub('\\d+th', ' <ENUM> ', text)\n",
    "    text = re.sub('\\d+rd', ' <ENUM> ', text)\n",
    "    text = re.sub('\\d+st', ' <ENUM> ', text)\n",
    "    text = re.sub('[\\+\\-]?\\d+.\\d+', ' <NUM> ', text)\n",
    "    text = re.sub('[\\+\\-]?\\d+,\\d+', ' <NUM> ', text)\n",
    "    text = re.sub('\\d+', ' <NUM> ', text)\n",
    "    # text = re.sub(r'\\w+\\.', '<SHORT>', text[0:-1]) + '.'\n",
    "    text = re.sub(',', ' , ', text)\n",
    "    text = re.sub(';', ' ; ', text)\n",
    "    text = re.sub(';', ' ; ', text)\n",
    "    text = re.sub('-', ' - ', text)\n",
    "    text = re.sub(':', ' : ', text)\n",
    "    text = re.sub('\\?', ' \\? ', text)\n",
    "    text = re.sub('\"', ' \" ', text)\n",
    "    text = re.sub(\"'\", \" ' \", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub('\\.', ' . ', text)\n",
    "    text = re.sub('\\(', ' ( ', text)\n",
    "    text = re.sub('\\)', ' ) ', text)\n",
    "    text = re.sub('\\.  \\.  \\.', ' ... ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['<SOS>', '<EOS>', '<PAD>', '<UNK>', '<NAN>', '<NUM>', '<TIME>', '<ENUM>', '<DATE>', '<PHONE>', '<EMAIL>', '<SHORT>', '<NAME>']\n",
    "tags_value = pd.DataFrame({'values': [i / (1+len(tags)) for i in range(1, 1+len(tags))]}, index=tags,)\n",
    "tags_value.loc['<SOS>', 'values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c =list(map(bad_patterns_to_tags_replaser2, data_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthes = np.array(list(map(lambda a: len(a.split(' ')), data_c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7476., 36989., 35532., 21685., 10836.,  5528.,  2474.,   871.,\n",
       "          219.,    42.]),\n",
       " array([ 2., 10., 18., 26., 34., 42., 50., 58., 66., 74., 82.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = []\n",
    "for i in data_c:\n",
    "    data_s += i.split()\n",
    "vocab = pd.Series(pd.Series(data_s).unique())\n",
    "vocab = vocab[vocab.apply(lambda a: a not in tags)]\n",
    "vocab = pd.concat([pd.Series(tags), vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169524,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procressing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_norm(text, l=30, sos='<SOS>', eos='<EOS>', pad='<PAD>'):\n",
    "    text_shorted = text[0:l]\n",
    "    text_padded = [sos] + text_shorted + [eos] + [pad for _ in range(l-len(text_shorted))]\n",
    "    return text_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_v = pd.Index(vocab)\n",
    "def text_tokenize(text):\n",
    "    return text.apply(lambda a: i_v.get_loc(a)) # [vocab[vocab==i].index[0] for i in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splited = pd.Series(data_c).apply(lambda a: a.split())\n",
    "data_splited = data_splited[data_splited.apply(len)>15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splited.apply(text_norm).apply(len).max(), data_splited.apply(text_norm).apply(len).min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\AppData\\Local\\Temp\\ipykernel_9032\\1317250533.py:1: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  data_normed = data_splited.apply(text_norm).apply(pd.Series)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2534.3823529411766"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normed = data_splited.apply(text_norm).apply(pd.Series)\n",
    "data_normed.shape[0]/34 # 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121652, 32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(34-1):\n",
    "    data_normed[i*3578:(i+1)*3578].to_csv(f'./../Data/anek_utf8/data_spited_normed_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tokenize = data_normed.apply(text_tokenize)\n",
    "data_tokenize.to_csv('./../Data/anek_utf8/data_tokenized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common = data_tokenize\n",
    "data_common['pre'] = data_splited.apply(' '.join)\n",
    "data_common.to_csv('./../Data/anek_utf8/data_common.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to torch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return tokenizer([sentence], padding=True, truncation=True, pad_to_multiple_of=32, max_length=32, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169524,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_check_data_spliter(data):\n",
    "    with torch.no_grad():\n",
    "        t = torch.tensor(list(map(int, data[0:32])))\n",
    "        output_data = torch.nn.functional.one_hot(t, vocab.shape[0])\n",
    "        d= tokenize(data[32])\n",
    "        input_data = vectorizer(**d)[0][0]\n",
    "    return output_data, input_data, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.datapipes.map.utils.SequenceWrapperMapDataPipe'>\n",
      "['0', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '18', '27', '18', '28', '29', '30', '18', '31', '32', '18', '33', '34', '35', '36', '18', '24', '1', 'Сразу после окончания Прямой линии , Путин пожаловался на дефицит интересных и актуальных вопросов , отметив , что критическое положение , слава богу , спасли осмысленные вопросы Шнурова , и очень своевременно поднятый вопрос о ситуации с Дзюбой .']\n",
      "['0', '56', '49', '57', '45', '58', '59', '60', '24', '61', '62', '21', '63', '64', '65', '18', '66', '67', '68', '69', '68', '45', '70', '28', '71', '72', '67', '68', '73', '74', '18', '1', 'Толкучка в атобусе . Автобус резко тормозит и женщина падает на рядом седящего свещеника , восклицает : \" Ого! \" . На что свещеник отвечает : \" Не ого , а ключ от храма \" .']\n",
      "['0', '79', '18', '80', '81', '82', '18', '28', '83', '84', '85', '86', '49', '87', '88', '49', '89', '90', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', 'Интересно , гадалка уже догадалась , что я еду к ней в Чертаново бухая в очко \\\\?']\n",
      "['0', '91', '92', '93', '18', '21', '94', '95', '24', '96', '18', '28', '97', '98', '18', '99', '100', '101', '45', '102', '103', '104', '105', '18', '106', '107', '90', '108', '102', '109', '18', '1', 'Идет одна бабка , на встречу другой и видит , что у той , полная сумка презервативов . - Зачем тебе старой , столько много \\\\? ! - Да , я вот слышала , опять идет подорожание цен , скоро будем хер сосать! А ты знаешь , какая я брезгливая .']\n"
     ]
    }
   ],
   "source": [
    "output_res = torchdata.datapipes.iter.IterableWrapper(['./../Data/anek_utf8/data_common.csv'])\n",
    "output_res_pipe = torchdata.datapipes.iter.FileOpener(output_res, mode='r', encoding='utf-8', length=data_common.shape[0])\n",
    "res_pipe = output_res_pipe.parse_csv(skip_lines=1, delimiter=',')\n",
    "res_pipe = torchdata.datapipes.map.SequenceWrapper(list(res_pipe))\n",
    "print_simple_data_pipe(res_pipe, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.datapipes.map.callable.MapperMapDataPipe'>\n",
      "(torch.Size([32, 169524]), torch.Size([32, 1024]), torch.Size([32]))\n",
      "(torch.Size([32, 169524]), torch.Size([32, 1024]), torch.Size([32]))\n",
      "(torch.Size([32, 169524]), torch.Size([32, 1024]), torch.Size([32]))\n",
      "(torch.Size([32, 169524]), torch.Size([32, 1024]), torch.Size([32]))\n"
     ]
    }
   ],
   "source": [
    "ready = res_pipe.map(input_data_check_data_spliter)\n",
    "print_simple_data_pipe(ready, n=3, f=lambda a: (a[0].shape, a[1].shape, a[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(batch):\n",
    "    d1, d2, d3 = [], [], []\n",
    "    for i, j, k in batch:\n",
    "        d1.append(i.unsqueeze(0))\n",
    "        d2.append(j.unsqueeze(0))\n",
    "        d3.append(k.unsqueeze(0))\n",
    "    return torch.concat(d1), torch.concat(d2), torch.concat(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torchdata.datapipes.map.Batcher(torchdata.datapipes.map.Shuffler(ready), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, emb_size, n_heads):\n",
    "        super(Attention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.wQ = (torch.nn.parameter.Parameter(torch.rand([n_heads, emb_size, emb_size])).to(device))\n",
    "        self.wK = torch.nn.parameter.Parameter(torch.rand([n_heads, emb_size, emb_size])).to(device)\n",
    "        self.wV = torch.nn.parameter.Parameter(torch.rand([n_heads, emb_size, emb_size])).to(device)\n",
    "        self.wO = torch.nn.parameter.Parameter(torch.rand([n_heads * emb_size, emb_size])).to(device)\n",
    "\n",
    "    def forward(self, en_out):\n",
    "        eo = en_out.clone()\n",
    "        for i in range(eo.shape[0]):\n",
    "            m = eo[i].unsqueeze(0)\n",
    "            eo[i] = self.iteration(m, m, m)\n",
    "        return eo\n",
    "\n",
    "    def iteration(self, Q: torch.tensor, K: torch.tensor, V: torch.tensor):\n",
    "        d = Q.shape[2]\n",
    "        s = Q.shape[1]\n",
    "        qp = Q.repeat(self.n_heads, 1, 1).bmm(self.wQ)\n",
    "        kp = K.repeat(self.n_heads, 1, 1).bmm(self.wK)\n",
    "        vp = V.repeat(self.n_heads, 1, 1).bmm(self.wV)\n",
    "        res = torch.softmax(qp.bmm(kp.transpose(1, 2))/d**0.5, 1)\n",
    "        res2 = (res.bmm(vp))\n",
    "        return res2.view(s, d * self.n_heads).mm(self.wO)\n",
    "\n",
    "att = Attention(128, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (embedding): Embedding(169524, 256)\n",
      "  (GRU): GRU(256, 1024, num_layers=2)\n",
      "  (fc): Linear(in_features=1024, out_features=169524, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, output_size):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.embedding_size = embedding_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    self.output_size = output_size\n",
    "    self.tag = True\n",
    "    self.embedding = torch.nn.Embedding(self.input_size, self.embedding_size)\n",
    "    self.GRU = torch.nn.GRU(self.embedding_size, hidden_size, num_layers)\n",
    "    self.fc = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "  def forward(self, x, hidden_state):\n",
    "    x = x.unsqueeze(0)\n",
    "    embedding = self.embedding(x)\n",
    "    outputs, hidden_state = self.GRU(embedding, hidden_state)\n",
    "    predictions = self.fc(outputs)\n",
    "    predictions = predictions.squeeze(0)\n",
    "    return predictions, hidden_state\n",
    "\n",
    "input_size_decoder = len(vocab)\n",
    "decoder_embedding_size = 256\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "output_size = len(vocab)\n",
    "\n",
    "decoder_gru = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, num_layers, output_size).to(device)\n",
    "print(decoder_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self, \n",
    "    input_vocab_size,\n",
    "    output_vocab_size,\n",
    "    decoder_embedding_size,\n",
    "    position_coording_matrix,\n",
    "    Decoder, \n",
    "    # Attention\n",
    "  ):\n",
    "    super(Seq2Seq, self).__init__()\n",
    "    self.input_vocab_size = input_vocab_size\n",
    "    self.output_vocab_size = output_vocab_size\n",
    "    self.encoder_embedding_size = encoder_embedding_size\n",
    "    self.decoder_embedding_size = decoder_embedding_size\n",
    "    self.position_coording_matrix = position_coording_matrix\n",
    "    self.encoder_embeder = torch.nn.Embedding(self.input_vocab_size, self.encoder_embedding_size)\n",
    "    self.decoder_embeder = torch.nn.Embedding(self.output_vocab_size, self.decoder_embedding_size)\n",
    "    self.Decoder = Decoder\n",
    "    # self.attention = Attention\n",
    "\n",
    "  def forward(self, source, target, tfr=0.2):\n",
    "    source = source.transpose(0, 1)\n",
    "    target = target.transpose(0, 1)\n",
    "    batch_size = source.shape[1]\n",
    "    target_len = target.shape[0]\n",
    "    target_vocab_size = self.output_vocab_size\n",
    "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "    hidden_state_encoder = source\n",
    "    x = target[0,:]\n",
    "    for i in range(1, target_len):\n",
    "      inDec = self.decoder_embeder(x.unsqueeze(0))\n",
    "      output, _ = self.Decoder(inDec, hidden_state_encoder)\n",
    "      outputs[i] = output\n",
    "      best_guess = output.argmax(1)\n",
    "      x = target[i] if np.random.random() < tfr else best_guess\n",
    "    return outputs.transpose(0, 1)\n",
    "\n",
    "\n",
    "input_size_decoder = len(vocab)\n",
    "encoder_embedding_size = 128\n",
    "decoder_embedding_size = 128\n",
    "model = Seq2Seq(input_size_encoder, input_size_decoder, encoder_embedding_size, decoder_embedding_size, position_coording_matrix, encoder_lstm, decoder_lstm, \n",
    "                # att\n",
    "                ).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in res:\n",
    "    y_b, x_b, t_b = join(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[239], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdecoder_gru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\5semak\\NLP_5_semak\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[233], line 16\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden_state):\n\u001b[0;32m     15\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m   embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m     17\u001b[0m   outputs, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRU(embedding, hidden_state)\n\u001b[0;32m     18\u001b[0m   predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(outputs)\n",
      "Cell \u001b[1;32mIn[233], line 16\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden_state):\n\u001b[0;32m     15\u001b[0m   x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m   embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m     17\u001b[0m   outputs, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRU(embedding, hidden_state)\n\u001b[0;32m     18\u001b[0m   predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(outputs)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\5semak\\NLP_5_semak\\NLP\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32md:\\5semak\\NLP_5_semak\\NLP\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoder_gru(t_b.to(device), x_b.to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
