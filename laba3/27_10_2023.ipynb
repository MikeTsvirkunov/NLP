{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torchdata\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['<SOS>', '<EOS>', '<PAD>', '<UNK>', '<NAN>', '<NUM>', '<TIME>', '<ENUM>', '<DATE>', '<PHONE>', '<EMAIL>', '<DOTS>', '<SHORT>', '<NAME>']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_patterns_to_tags_replaser(text: str):\n",
    "    text = re.sub(r'\\d+\\:\\d+\\:\\d+', ' <TIME> ', text)\n",
    "    text = re.sub(r'\\d+\\:\\d+', ' <TIME> ', text)\n",
    "    text = re.sub(r'\\+{,1}\\d{1,3}\\({,1}[\\-\\s]{,1}\\d{3}\\){,1}[\\-\\s]{,1}\\d{3}[\\-\\s]{,1}\\d{2}[\\-\\s]{,1}\\d{2}', ' <PHONE> ', text)\n",
    "    text = re.sub('\\d+/\\d+/\\d+', ' <DATE> ', text)\n",
    "    text = re.sub('\\d+-\\d+-\\d+', ' <DATE> ', text)\n",
    "    text = re.sub('\\d+th', ' <ENUM> ', text)\n",
    "    text = re.sub('\\d+rd', ' <ENUM> ', text)\n",
    "    text = re.sub('\\d+st', ' <ENUM> ', text)\n",
    "    text = re.sub('[\\+\\-]?\\d+.\\d+', ' <NUM> ', text)\n",
    "    text = re.sub('[\\+\\-]?\\d+,\\d+', ' <NUM> ', text)\n",
    "    text = re.sub('\\d+', ' <NUM> ', text)\n",
    "    # text = re.sub(r'\\w+\\.', '<SHORT>', text[0:-1]) + '.'\n",
    "    text = re.sub(',', ' , ', text)\n",
    "    text = re.sub(';', ' ; ', text)\n",
    "    text = re.sub(';', ' ; ', text)\n",
    "    text = re.sub('-', ' - ', text)\n",
    "    text = re.sub(':', ' : ', text)\n",
    "    text = re.sub('\\?', ' \\? ', text)\n",
    "    text = re.sub('\\...', ' <DOTS> ', text)\n",
    "    text = re.sub('\"', ' \" ', text)\n",
    "    text = re.sub(\"'s\", \" 's \", text)\n",
    "    text = re.sub(\"'d\", \" 'd \", text)\n",
    "    text = re.sub(\"'re\", \" 're \", text)\n",
    "    text = re.sub(\"'m\", \" 'm \", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub('\\.', ' . ', text)\n",
    "    return text[0:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i 'd wake up at <TIME> or <TIME> , go <DOTS> downstairs , and the <NUM> % , <NUM> % , <NUM> % , <NUM> % , <NUM> % , <NUM> % , front phones [ <PHONE> , <PHONE> , <PHONE> , <PHONE> , <PHONE> , <PHONE> ] door would be open - <NUM> beers in the kitchen and <ENUM> , <ENUM> , <ENUM> living room and nobody in the house on <DATE> or <DATE>  .\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_patterns_to_tags_replaser(\n",
    "    \"I'd wake up at 7:30 or 100:02:20, go... downstairs, and the 123,45%, 123.45%, +123,45%, -123,45%, +123.45%, -123.45%, front phones [+7 999 444 55 66, +7-999-444-55-66, +79994445566, 79994445566, +7(999)-444-55-66, +7(999)-444-5566] door would be open - 600 beers in the kitchen and 20th, 3rd, 1st living room and nobody in the house on 12/12/2012 or 12-12-2012.\".lower()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_simple_data_pipe(date_pipe: torchdata.datapipes.iter.IterDataPipe, n=10) -> None:\n",
    "  print(type(date_pipe))\n",
    "  x = 0\n",
    "  for sample in date_pipe:\n",
    "    print(sample)\n",
    "    if x == n:\n",
    "      break\n",
    "    x +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/1mcorpus/corpus.en_ru.1m.en', encoding='utf-8') as f:\n",
    "    eng = f.read().split('\\n')\n",
    "with open('../Data/1mcorpus/corpus.en_ru.1m.ru', encoding='utf-8') as f:\n",
    "    rus = f.read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'eng': eng, 'rus': rus}).to_csv('../Data/1mcorpus/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(bad_patterns_to_tags_replaser(max(eng + rus, key=len)).split(' '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset using torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_rus_pairs = torchdata.datapipes.iter.IterableWrapper(['../Data/1mcorpus/data.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_rus_pairs_pipe = torchdata.datapipes.iter.FileOpener(eng_rus_pairs, mode='r', encoding='utf-8', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchdata.datapipes.iter.util.plain_text_reader.CSVParserIterDataPipe'>\n",
      "[\"This new development in Harry's character may be a disappointment to those readers who enjoyed his old vindictive ways, but it also reinforces the position of pro-Potter people who do not see beneath the surface appearance of the characters and plots.\", 'Такое развитие характера Гарри может разочаровать читателей, полюбивших его былую мстительность, но с другой стороны это преображение укрепляет позицию тех, кто не видит глубже сюжета и изображения героев.']\n",
      "['A nondisclosure clause in the final settlement (the band is back on Elektra) prevents Ulrich, an irrepressible motormouth, from providing any juicy contractual details.', 'Решение суда (группа вернулась под крыло к Elektra Entertainment) предотвратило дальнейшие нападки со стороны неугомонного Ульриха и не позволило ему обнародовать детали нового контракта.']\n",
      "[\"When you're 18 or 19 years old, you have that gang mentality in your band.\", 'Когда тебе 18 или 19 лет, легко перенимать бандитские повадки и переносить их в группу.']\n",
      "['Now you have Black Sabbath and Kiss tribute albums.', 'А сейчас куча триьютов тем же самым BLACK SABBATH и KISS.']\n"
     ]
    }
   ],
   "source": [
    "eng_rus_pairs_pipe_parsed = eng_rus_pairs_pipe.parse_csv(skip_lines=1, delimiter=',')\n",
    "print_simple_data_pipe(eng_rus_pairs_pipe_parsed, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "  return [t for t in bad_patterns_to_tags_replaser(text.lower()).split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens_eng(data_iter: torchdata.datapipes.iter.IterDataPipe):\n",
    "  for eng, rus in data_iter:\n",
    "    yield tokenize(eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens_rus(data_iter: torchdata.datapipes.iter.IterDataPipe):\n",
    "  for eng, rus in data_iter:\n",
    "    yield tokenize(rus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "['this', 'new', 'development', 'in', 'harry', \"'s\", 'character', 'may', 'be', 'a', 'disappointment', 'to', 'those', 'readers', 'who', 'enjoyed', 'his', 'old', 'vindictive', 'ways', ',', 'but', 'it', 'also', 'reinforces', 'the', 'position', 'of', 'pro', '-', 'potter', 'people', 'who', 'do', 'not', 'see', 'beneath', 'the', 'surface', 'appearance', 'of', 'the', 'characters', 'and', 'plots', '.']\n",
      "['a', 'nondisclosure', 'clause', 'in', 'the', 'final', 'settlement', '(the', 'band', 'is', 'back', 'on', 'elektra)', 'prevents', 'ulrich', ',', 'an', 'irrepressible', 'motormouth', ',', 'from', 'providing', 'any', 'juicy', 'contractual', 'details', '.']\n",
      "['when', 'you', \"'re\", '<NUM>', 'or', '<NUM>', 'years', 'old', ',', 'you', 'have', 'that', 'gang', 'mentality', 'in', 'your', 'band', '.']\n",
      "['now', 'you', 'have', 'black', 'sabbath', 'and', 'kiss', 'tribute', 'albums', '.']\n"
     ]
    }
   ],
   "source": [
    "print_simple_data_pipe(yield_tokens_eng(eng_rus_pairs_pipe_parsed), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "['такое', 'развитие', 'характера', 'гарри', 'может', 'разочаровать', 'читателей', ',', 'полюбивших', 'его', 'былую', 'мстительность', ',', 'но', 'с', 'другой', 'стороны', 'это', 'преображение', 'укрепляет', 'позицию', 'тех', ',', 'кто', 'не', 'видит', 'глубже', 'сюжета', 'и', 'изображения', 'героев', '.']\n",
      "['решение', 'суда', '(группа', 'вернулась', 'под', 'крыло', 'к', 'elektra', 'entertainment)', 'предотвратило', 'дальнейшие', 'нападки', 'со', 'стороны', 'неугомонного', 'ульриха', 'и', 'не', 'позволило', 'ему', 'обнародовать', 'детали', 'нового', 'контракта', '.']\n",
      "['когда', 'тебе', '<NUM>', 'или', '<NUM>', 'лет', ',', 'легко', 'перенимать', 'бандитские', 'повадки', 'и', 'переносить', 'их', 'в', 'группу', '.']\n",
      "['а', 'сейчас', 'куча', 'триьютов', 'тем', 'же', 'самым', 'black', 'sabbath', 'и', 'kiss', '.']\n"
     ]
    }
   ],
   "source": [
    "print_simple_data_pipe(yield_tokens_rus(eng_rus_pairs_pipe_parsed), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    yield_tokens_eng(eng_rus_pairs_pipe_parsed),\n",
    "    min_freq=2,\n",
    "    specials=tags,\n",
    "    special_first=True\n",
    ")\n",
    "eng_vocab.set_default_index(eng_vocab['<UNK>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    yield_tokens_rus(eng_rus_pairs_pipe_parsed),\n",
    "    min_freq=2,\n",
    "    specials=tags,\n",
    "    special_first=True\n",
    ")\n",
    "rus_vocab.set_default_index(rus_vocab['<UNK>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('./eng_vocab.pkl'):\n",
    "    with open('./eng_vocab.pkl', 'wb') as f:\n",
    "        pickle.dump(eng_vocab, f)\n",
    "else:\n",
    "    print('already exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./rus_vocab.pkl'):\n",
    "    with open('./rus_vocab.pkl', 'wb') as f:\n",
    "        pickle.dump(rus_vocab, f)\n",
    "else:\n",
    "    print('already exist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_rus = Word2Vec(\n",
    "    sentences=list(yield_tokens_rus(eng_rus_pairs_pipe_parsed)),\n",
    "    vector_size=128,\n",
    "    min_count=1, \n",
    "    window=5, \n",
    "    workers=4, \n",
    "    epochs=10, \n",
    "    compute_loss=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_eng = Word2Vec(\n",
    "    sentences=list(yield_tokens_eng(eng_rus_pairs_pipe_parsed)),\n",
    "    vector_size=128,\n",
    "    min_count=1,\n",
    "    window=5,\n",
    "    workers=4,\n",
    "    epochs=10,\n",
    "    compute_loss=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./w2v_eng.model'):\n",
    "    w2v_eng.save('./w2v_eng.model')\n",
    "else:\n",
    "    print('already exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./w2v_rus.model'):\n",
    "    w2v_eng.save('./w2v_rus.model')\n",
    "else:\n",
    "    print('already exist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_transform(vocab: torchtext.vocab.Vocab) -> torchtext.transforms.Sequential:\n",
    "    text_tranform = torchtext.transforms.Sequential(\n",
    "        torchtext.transforms.VocabTransform(vocab=vocab),\n",
    "        torchtext.transforms.AddToken(vocab['<SOS>'], begin=True),\n",
    "        torchtext.transforms.AddToken(vocab['<EOS>'], begin=False)\n",
    "    )\n",
    "    return text_tranform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vocab_transform(pair):\n",
    "    return (\n",
    "        vocab_transform(eng_vocab)(tokenize(pair[0])),\n",
    "        vocab_transform(rus_vocab)(tokenize(pair[1]))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vocab_vectorise(pair):\n",
    "    eng = []\n",
    "    rus = []\n",
    "    for i in pair[0]:\n",
    "        if i < len(tags):\n",
    "            eng.append(np.ones(w2v_eng.vector_size) * i / len(tags))\n",
    "        else:\n",
    "            eng.append(w2v_eng.wv[i].tolist())\n",
    "    for i in pair[1]:\n",
    "        if i < len(tags):\n",
    "            rus.append(np.ones(w2v_rus.vector_size) * i / len(tags))\n",
    "        else:\n",
    "            rus.append(w2v_rus.wv[i].tolist())\n",
    "    return (torch.tensor(eng), torch.tensor(rus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.datapipes.iter.callable.MapperIterDataPipe'>\n",
      "([0, 33, 67, 110, 18, 4588, 38, 1357, 85, 30, 19, 9970, 17, 127, 3579, 68, 3764, 58, 302, 46414, 799, 13, 51, 27, 64, 16778, 12, 564, 15, 2069, 20, 10235, 77, 68, 88, 37, 161, 6151, 12, 1471, 2332, 15, 12, 2435, 16, 7153, 14, 1], [0, 459, 370, 1559, 4596, 52, 75283, 6306, 12, 290035, 37, 70130, 276120, 12, 35, 19, 248, 158, 29, 71785, 13062, 2235, 170, 12, 123, 20, 3941, 8887, 26763, 15, 1266, 8854, 13, 1])\n",
      "([0, 19, 57752, 5232, 18, 12, 941, 2080, 914, 1592, 21, 231, 25, 3, 5438, 24176, 13, 44, 35133, 124305, 13, 35, 899, 79, 20172, 6594, 1093, 14, 1], [0, 264, 917, 31834, 11454, 104, 17778, 24, 136993, 156241, 75070, 7429, 31135, 83, 158, 3, 121214, 15, 20, 3901, 188, 35976, 2900, 450, 4622, 13, 1])\n",
      "([0, 66, 32, 469, 5, 34, 5, 111, 302, 13, 32, 41, 23, 7985, 7725, 18, 56, 1592, 14, 1], [0, 57, 1203, 5, 28, 5, 99, 12, 593, 71555, 138968, 100289, 15, 16696, 46, 14, 1428, 13, 1])\n",
      "([0, 122, 32, 41, 845, 8916, 16, 8366, 8757, 5961, 14, 1], [0, 30, 195, 27232, 3, 92, 64, 518, 14647, 96304, 15, 64463, 13, 1])\n"
     ]
    }
   ],
   "source": [
    "eng_rus_pairs_pipe_transformed = eng_rus_pairs_pipe_parsed.map(apply_vocab_transform)\n",
    "print_simple_data_pipe(eng_rus_pairs_pipe_transformed, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 128]) torch.Size([34, 128])\n",
      "torch.Size([29, 128]) torch.Size([27, 128])\n",
      "torch.Size([20, 128]) torch.Size([19, 128])\n",
      "torch.Size([12, 128]) torch.Size([14, 128])\n"
     ]
    }
   ],
   "source": [
    "eng_rus_pairs_pipe_vectorized = eng_rus_pairs_pipe_transformed.map(apply_vocab_vectorise)\n",
    "x = 0\n",
    "for i in eng_rus_pairs_pipe_vectorized:\n",
    "    print(i[0].shape, i[1].shape)\n",
    "    if x == 3:\n",
    "        break\n",
    "    x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_rus_pairs_pipe_batch = eng_rus_pairs_pipe_transformed.bucketbatch(\n",
    "    batch_size=256,\n",
    "    use_in_batch_shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(pair):\n",
    "    examples, targets = zip(*pair)\n",
    "    return examples, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_padding(pair):\n",
    "    print(len(pair[0]))\n",
    "    return (torchtext.transforms.ToTensor(eng_vocab['<PAD>'])([list(pair[0])]), torchtext.transforms.ToTensor(eng_vocab['<PAD>'])([list(pair[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "torch.Size([1, 48]) torch.Size([1, 34])\n",
      "(tensor([[    0,    33,    67,   110,    18,  4588,    38,  1357,    85,    30,\n",
      "            19,  9970,    17,   127,  3579,    68,  3764,    58,   302, 46414,\n",
      "           799,    13,    51,    27,    64, 16778,    12,   564,    15,  2069,\n",
      "            20, 10235,    77,    68,    88,    37,   161,  6151,    12,  1471,\n",
      "          2332,    15,    12,  2435,    16,  7153,    14,     1]]), tensor([[     0,    459,    370,   1559,   4596,     52,  75283,   6306,     12,\n",
      "         290035,     37,  70130, 276120,     12,     35,     19,    248,    158,\n",
      "             29,  71785,  13062,   2235,    170,     12,    123,     20,   3941,\n",
      "           8887,  26763,     15,   1266,   8854,     13,      1]]))\n",
      "29\n",
      "torch.Size([1, 29]) torch.Size([1, 27])\n",
      "(tensor([[     0,     19,  57752,   5232,     18,     12,    941,   2080,    914,\n",
      "           1592,     21,    231,     25,      3,   5438,  24176,     13,     44,\n",
      "          35133, 124305,     13,     35,    899,     79,  20172,   6594,   1093,\n",
      "             14,      1]]), tensor([[     0,    264,    917,  31834,  11454,    104,  17778,     24, 136993,\n",
      "         156241,  75070,   7429,  31135,     83,    158,      3, 121214,     15,\n",
      "             20,   3901,    188,  35976,   2900,    450,   4622,     13,      1]]))\n",
      "20\n",
      "torch.Size([1, 20]) torch.Size([1, 19])\n",
      "(tensor([[   0,   66,   32,  469,    5,   34,    5,  111,  302,   13,   32,   41,\n",
      "           23, 7985, 7725,   18,   56, 1592,   14,    1]]), tensor([[     0,     57,   1203,      5,     28,      5,     99,     12,    593,\n",
      "          71555, 138968, 100289,     15,  16696,     46,     14,   1428,     13,\n",
      "              1]]))\n",
      "12\n",
      "torch.Size([1, 12]) torch.Size([1, 14])\n",
      "(tensor([[   0,  122,   32,   41,  845, 8916,   16, 8366, 8757, 5961,   14,    1]]), tensor([[    0,    30,   195, 27232,     3,    92,    64,   518, 14647, 96304,\n",
      "            15, 64463,    13,     1]]))\n"
     ]
    }
   ],
   "source": [
    "eng_rus_pairs_pipe_eqlength = eng_rus_pairs_pipe_transformed.map(apply_padding)\n",
    "x = 0\n",
    "for i in eng_rus_pairs_pipe_eqlength:\n",
    "    print(i[0].shape, i[1].shape)\n",
    "    print(i)\n",
    "    if x == 3:\n",
    "        break\n",
    "    x += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = torchdata.datapipes.iter.IterableWrapper(['../Data/1mcorpus/corpus.en_ru.1m.en'])\n",
    "rus = torchdata.datapipes.iter.IterableWrapper(['../Data/1mcorpus/corpus.en_ru.1m.ru'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pipe = torchdata.datapipes.iter.FileOpener(eng, mode='r', encoding='utf-8', )\n",
    "rus_pipe = torchdata.datapipes.iter.FileOpener(rus, mode='r', encoding='utf-8', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchdata.datapipes.iter.util.plain_text_reader.CSVParserIterDataPipe'>\n",
      "[\"This new development in Harry's character may be a disappointment to those readers who enjoyed his old vindictive ways, but it also reinforces the position of pro-Potter people who do not see beneath the surface appearance of the characters and plots.\"]\n",
      "['A nondisclosure clause in the final settlement (the band is back on Elektra) prevents Ulrich, an irrepressible motormouth, from providing any juicy contractual details.']\n",
      "[\"When you're 18 or 19 years old, you have that gang mentality in your band.\"]\n",
      "['Now you have Black Sabbath and Kiss tribute albums.']\n",
      "<class 'torchdata.datapipes.iter.util.plain_text_reader.CSVParserIterDataPipe'>\n",
      "['Такое развитие характера Гарри может разочаровать читателей, полюбивших его былую мстительность, но с другой стороны это преображение укрепляет позицию тех, кто не видит глубже сюжета и изображения героев.']\n",
      "['Решение суда (группа вернулась под крыло к Elektra Entertainment) предотвратило дальнейшие нападки со стороны неугомонного Ульриха и не позволило ему обнародовать детали нового контракта.']\n",
      "['Когда тебе 18 или 19 лет, легко перенимать бандитские повадки и переносить их в группу.']\n",
      "['А сейчас куча триьютов тем же самым BLACK SABBATH и KISS.']\n"
     ]
    }
   ],
   "source": [
    "eng_pipe_parsed = eng_pipe.parse_csv(skip_lines=0, delimiter='\\n')\n",
    "print_simple_data_pipe(eng_pipe_parsed, 3)\n",
    "rus_pipe_parsed = rus_pipe.parse_csv(skip_lines=0, delimiter='\\n')\n",
    "print_simple_data_pipe(rus_pipe_parsed, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "  return [bad_patterns_to_tags_replaser(t.lower()) for t in text.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter: torchdata.datapipes.iter.IterDataPipe):\n",
    "  for example in data_iter:\n",
    "    yield tokenize(example[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    yield_tokens(eng_pipe_parsed),\n",
    "    min_freq=2,\n",
    "    specials=tags,\n",
    "    special_first=True\n",
    ")\n",
    "eng_vocab.set_default_index(eng_vocab['<UNK>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    yield_tokens(rus_pipe_parsed),\n",
    "    min_freq=2,\n",
    "    specials=tags,\n",
    "    special_first=True\n",
    ")\n",
    "rus_vocab.set_default_index(rus_vocab['<UNK>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_transform(vocab: torchtext.vocab.Vocab) -> torchtext.transforms.Sequential:\n",
    "    text_tranform = torchtext.transforms.Sequential(\n",
    "        torchtext.transforms.VocabTransform(vocab=vocab),\n",
    "        torchtext.transforms.AddToken(vocab['<SOS>'], begin=True),\n",
    "        torchtext.transforms.AddToken(vocab['<EOS>'], begin=False)\n",
    "    )\n",
    "    return text_tranform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vocab_transform_eng(text: list[str]):\n",
    "    return vocab_transform(eng_vocab)(tokenize(text[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pipe_mod = eng_pipe_parsed.map(apply_vocab_transform_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
